{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb2f690-b310-4652-8257-cacc80bfff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a6ab3f-ffe8-4eaf-8e5b-5ac09d3f325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "mimic_df = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Dataset_Predicting Hospital\\mimic_iii_data.csv\")\n",
    "diabetes_df = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Dataset_Predicting Hospital\\diabetic_data.csv\")\n",
    "\n",
    "# Merge datasets on patient ID\n",
    "merged_df = pd.merge(diabetes_df, mimic_df, left_on=\"patient_nbr\", right_on=\"Patient_ID\", how=\"inner\")\n",
    "merged_df.drop(columns=[\"Patient_ID\"], inplace=True)\n",
    "\n",
    "# Replace missing values marked as '?'\n",
    "merged_df.replace(\"?\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cbb795-a1f1-425b-95e6-da79300233ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing numerical values with median\n",
    "num_cols = merged_df.select_dtypes(include=[np.number]).columns\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "merged_df[num_cols] = num_imputer.fit_transform(merged_df[num_cols])\n",
    "\n",
    "# Impute missing categorical values with mode\n",
    "cat_cols = merged_df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    merged_df[col].fillna(merged_df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "573489eb-d6b6-4960-ae00-afa224f53d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Categorical Variables\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_df[col] = le.fit_transform(merged_df[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8230aa01-89f3-4bb0-94a8-5e1845d17834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features & Target Variable\n",
    "# Convert 'readmitted' column: '>30' and '<30' â†’ 1 (readmitted), 'NO' â†’ 0 (not readmitted)\n",
    "merged_df['readmitted'] = merged_df['readmitted'].replace({'>30': 1, '<30': 1, 'NO': 0})\n",
    "\n",
    "# Define features and target\n",
    "X = merged_df.drop(columns=[\"readmitted\"])\n",
    "y = merged_df[\"readmitted\"]\n",
    "\n",
    "# Ensure dataset is large enough before splitting\n",
    "if X.shape[0] < 50:\n",
    "    raise ValueError(f\"Insufficient data for training. Only {X.shape[0]} samples available.\")\n",
    "\n",
    "# Train-test split (80% train, 20% test, stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22f5e915-ea93-4f9f-9aa5-409676e9d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f57308-df5e-4007-938c-5c4aa9d26471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    \n",
    "    # Predictions on train and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\"Train Accuracy\": train_accuracy, \"Test Accuracy\": test_accuracy}\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{name} Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"{name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e47cb4-c9b2-4607-b863-74cfe87f9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results dictionary to DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.sort_values(by=\"Test Accuracy\", ascending=False, inplace=True)\n",
    "print(results_df)\n",
    "\n",
    "# Bar plot of model performance\n",
    "plt.figure(figsize=(10, 5))\n",
    "results_df.plot(kind=\"bar\", figsize=(10, 5), colormap=\"viridis\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Comparison (Train & Test Accuracy)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5241ea-7173-4430-a5ed-7935d09e49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Time in Hospital\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(merged_df['time_in_hospital'], bins=20, kde=True)\n",
    "plt.title(\"Distribution of Time in Hospital\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Number of Medications\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(merged_df['num_medications'], bins=20, kde=True)\n",
    "plt.title(\"Distribution of Number of Medications\")\n",
    "plt.xlabel(\"Number of Medications\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation Matrix\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(merged_df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix - Diabetes Data\")\n",
    "plt.show()\n",
    "\n",
    "# Readmission Counts\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x='readmitted', data=merged_df, palette=\"pastel\")\n",
    "plt.title(\"Readmission Counts\")\n",
    "plt.xlabel(\"Readmitted (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Time in Hospital by Readmission Status\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot(x='readmitted', y='time_in_hospital', data=merged_df, palette=\"muted\")\n",
    "plt.title(\"Time in Hospital by Readmission Status\")\n",
    "plt.xlabel(\"Readmitted (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Time in Hospital (days)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513877f8-7e59-462d-bb27-8fd49d5ecfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
